{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as thub\n",
    "import bert\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sample(context):\n",
    "    \n",
    "    \"\"\"\n",
    "    To be applied over Spark dataframe.\n",
    "    Takes a string and converts it to token IDs via bert_tokenizer,\n",
    "    adding the necessary beginning and end tokens\n",
    "\n",
    "    Returns: Array of bert token ids for each row of Spark dataframe (requires udf)\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenized = [\"[CLS]\"] + tokenizer.tokenize(context) + [\"[SEP]\"]\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_epoch_df(sarcastic, non_sarcastic, ratio, n_epochs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns: Ndarray of equal label distribution over which \n",
    "    we can perform mini-batch gradient descent. Each generated df is\n",
    "    to be iterator over multiple times during training\n",
    "    \"\"\"\n",
    "    \n",
    "    number = 0\n",
    "    while number < n_epochs:\n",
    "        non_sarc_samp = non_sarcastic.sample(ratio) # making label dist equal\n",
    "        \n",
    "        # combine sampled non_sarcastic and whole sarcastic\n",
    "        epoch_df = sarcastic.union(non_sarc_samp)\n",
    "        \n",
    "        # tokenize context column via spark udf\n",
    "        tokenize_sample_udf = F.udf(tokenize_sample, ArrayType(IntegerType()))\n",
    "        epoch_df = epoch_df.withColumn(\"tokens\", tokenize_sample_udf(epoch_df.context))\n",
    "        \n",
    "        # split into X and y numpy arrays\n",
    "        #X = np.array(epoch_df.select('tokens').collect())\n",
    "        #y = np.array(epoch_df.select('label').collect())\n",
    "        \n",
    "        X = epoch_df.select('tokens')\n",
    "        y = epoch_df.select('label')\n",
    "        \n",
    "        # yield one call at a time\n",
    "        yield X, y\n",
    "        number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT model and tokenizer\n",
    "\n",
    "bert_layer, tokenizer = model_utils.init_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark context\n",
    "\n",
    "sc, spark = model_utils.init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sarcastic samples, non-sarcastic samples, and the ratio between the two\n",
    "\n",
    "sarcastic, non_sarcastic, ratio = model_utils.load_data(spark, \n",
    "                                                        bucket_name=\"sarc-bucket-5\", \n",
    "                                                        dataset=\"politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate epoch\n",
    "\n",
    "generator = generate_epoch_df(sarcastic, non_sarcastic, ratio, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 273 ms, sys: 3.36 ms, total: 277 ms\n",
      "Wall time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "%time X,y = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 875 ms, sys: 7.99 ms, total: 883 ms\n",
      "Wall time: 9.91 s\n"
     ]
    }
   ],
   "source": [
    "%time new = np.array(X.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = X.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 4208,\n",
       " 117,\n",
       " 1133,\n",
       " 6557,\n",
       " 1110,\n",
       " 20560,\n",
       " 113,\n",
       " 2452,\n",
       " 1106,\n",
       " 22679,\n",
       " 1116,\n",
       " 114,\n",
       " 1137,\n",
       " 14284,\n",
       " 113,\n",
       " 2452,\n",
       " 1106,\n",
       " 181,\n",
       " 24851,\n",
       " 24279,\n",
       " 1116,\n",
       " 114,\n",
       " 119,\n",
       " 2809,\n",
       " 21752,\n",
       " 2059,\n",
       " 1107,\n",
       " 153,\n",
       " 2591,\n",
       " 13360,\n",
       " 9741,\n",
       " 4744,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: \\ ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda update pandas -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandas 0.24.0\n",
      "Uninstalling pandas-0.24.0:\n",
      "  Successfully uninstalled pandas-0.24.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas==0.24.0\n",
      "  Using cached pandas-0.24.0-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas==0.24.0) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas==0.24.0) (1.14.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from pandas==0.24.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.24.0) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pandas==0.23.0 -y\n",
    "!pip install pandas==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = X.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([101, 4208, 117, 1133, 6557, 1110, 20560, 113, 2452, 1106, 22679, 1116, 114, 1137, 14284, 113, 2452, 1106, 181, 24851, 24279, 1116, 114, 119, 2809, 21752, 2059, 1107, 153, 2591, 13360, 9741, 4744, 119, 102])],\n",
       "       [list([101, 12357, 112, 189, 1142, 170, 1632, 22275, 117, 8343, 2256, 1150, 5115, 1256, 21699, 1176, 3379, 2001, 12541, 1106, 1712, 1122, 3589, 1105, 4594, 1656, 1104, 1172, 136, 146, 112, 182, 1612, 1774, 1106, 8429, 2490, 112, 188, 2489, 1110, 1280, 1106, 4989, 170, 9908, 15867, 1309, 5940, 1254, 119, 2160, 117, 1133, 1517, 1195, 1838, 8077, 1158, 1172, 1107, 170, 8539, 117, 1105, 1173, 17400, 1172, 2469, 1106, 2218, 1614, 1115, 2999, 1234, 1138, 2469, 1106, 117, 1152, 1209, 5397, 1838, 1909, 1977, 1106, 5890, 1152, 1336, 1138, 170, 4910, 2463, 1105, 1209, 5397, 1136, 1712, 1122, 5346, 1181, 1656, 119, 102])],\n",
       "       [list([101, 5651, 5797, 1114, 4067, 11981, 1107, 24993, 1337, 2869, 171, 15243, 5815, 106, 102])],\n",
       "       ...,\n",
       "       [list([101, 1192, 1137, 1172, 119, 1337, 112, 188, 1293, 1240, 6380, 1267, 1122, 119, 1220, 1274, 112, 189, 1920, 1115, 1128, 1138, 1155, 1292, 4681, 119, 1192, 1274, 112, 189, 4841, 1116, 17770, 1106, 1147, 188, 3186, 21361, 1596, 4097, 1104, 6489, 1177, 1128, 1132, 1126, 3437, 1137, 2400, 1106, 1292, 1441, 119, 2096, 1736, 1147, 2912, 1106, 2140, 16757, 1366, 1110, 10298, 119, 102])],\n",
       "       [list([101, 146, 1450, 1184, 1115, 1156, 1129, 1196, 146, 14376, 1122, 119, 1262, 146, 1238, 112, 189, 1256, 2824, 25417, 21198, 1112, 170, 5102, 119, 1599, 1240, 1176, 1143, 1105, 1138, 1562, 1122, 1177, 1277, 1128, 5363, 1122, 119, 102])],\n",
       "       [list([101, 146, 1138, 4531, 7591, 3245, 117, 1185, 4106, 119, 2508, 1315, 117, 1646, 10044, 119, 102])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
