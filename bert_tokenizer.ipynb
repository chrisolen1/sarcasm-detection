{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading https://files.pythonhosted.org/packages/11/e0/1264990c559fb945cfb6664742001608e1ed8359eeec6722830ae085062b/sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.85\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!python3.7 -m pip install sentencepiece\n",
    "!python3.7 -m pip install bert-for-tf2\n",
    "!python3.7 -m pip install tensorflow_hub\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as thub\n",
    "import bert\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layer = thub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_wwm_cased_L-24_H-1024_A-16/1\",\n",
    "                            trainable=True)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "tokenizer = BertTokenizer(vocabulary_file, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pyspark.SparkConf().setAll([(\"spark.dynamicAllocation.enabled\",\"True\"),\n",
    "                                    (\"spark.executor.cores\",\"2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=config)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 ms, sys: 3.98 ms, total: 15.8 ms\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%time tsarc = spark.read.csv(\"gs://sarc-bucket-5/reddit_trunc.csv\", inferSchema=True, header=False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns: \n",
    "\n",
    "tsarc = tsarc.withColumnRenamed('_c0','label').withColumnRenamed('_c1','subreddit').withColumnRenamed('_c2','context')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------------------+\n",
      "|label|subreddit|             context|\n",
      "+-----+---------+--------------------+\n",
      "|    0| Portland|All these fucking...|\n",
      "|    0|     milf|Mother of one on ...|\n",
      "|    0| gonewild|{F}uckable? ;) Th...|\n",
      "|    0| politics|Took a loan. The ...|\n",
      "|    0|     pics|I see your kitche...|\n",
      "|    0| politics|Man, that was pol...|\n",
      "|    0|  atheism|\"Met my first fun...|\n",
      "|    0|     gifs|Emma Watson danci...|\n",
      "|    0|    ducks|The Duck is losin...|\n",
      "|    0|      CFB|I would just like...|\n",
      "+-----+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+\n",
      "|label|subreddit|context|\n",
      "+-----+---------+-------+\n",
      "|    0|      799|    799|\n",
      "+-----+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tsarc.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsarc = tsarc.where(F.col(\"context\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+\n",
      "|label|subreddit|context|\n",
      "+-----+---------+-------+\n",
      "|    0|        0|      0|\n",
      "+-----+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tsarc.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sample(context):\n",
    "    \n",
    "    \"\"\"\n",
    "    To be applied over dataframe.\n",
    "    Takes a string and converts it to token IDs via BERT tokenizer,\n",
    "    adding the necessary beginning and end tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenized = [\"[CLS]\"] + tokenizer.tokenize(context) + [\"[SEP]\"]\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "    \n",
    "    return ids\n",
    "\n",
    "tokenize_sample_udf = F.udf(tokenize_sample, ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsarc = tsarc.withColumn(\"tokens\", tokenize_sample_udf(tsarc.context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+\n",
      "|label|          subreddit|              tokens|\n",
      "+-----+-------------------+--------------------+\n",
      "|    0|           Portland|[101, 1398, 1292,...|\n",
      "|    0|               milf|[101, 4872, 1104,...|\n",
      "|    0|           gonewild|[101, 196, 143, 1...|\n",
      "|    0|           politics|[101, 6466, 1377,...|\n",
      "|    0|               pics|[101, 146, 1267, ...|\n",
      "|    0|           politics|[101, 2268, 117, ...|\n",
      "|    0|            atheism|[101, 107, 19415,...|\n",
      "|    0|               gifs|[101, 4913, 7422,...|\n",
      "|    0|              ducks|[101, 1109, 16627...|\n",
      "|    0|                CFB|[101, 146, 1156, ...|\n",
      "|    0|              funny|[101, 1284, 2028,...|\n",
      "|    0|              funny|[101, 138, 16723,...|\n",
      "|    0|              funny|[101, 1135, 112, ...|\n",
      "|    0|          AskReddit|[101, 5749, 1207,...|\n",
      "|    0|                aww|[101, 107, 107, 1...|\n",
      "|    0|      todayilearned|[101, 157, 17656,...|\n",
      "|    0|PoliticalDiscussion|[101, 2082, 7691,...|\n",
      "|    0|          AskReddit|[101, 6682, 1118,...|\n",
      "|    0|       IncestComics|[101, 1422, 4126,...|\n",
      "|    0|      todayilearned|[101, 157, 17656,...|\n",
      "+-----+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc = tsarc.drop('context')\n",
    "tsarc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_format_udf = F.udf(lambda x: str(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+--------------------+\n",
      "|label|          subreddit|              tokens|       tokens_string|\n",
      "+-----+-------------------+--------------------+--------------------+\n",
      "|    0|           Portland|[101, 1398, 1292,...|[101, 1398, 1292,...|\n",
      "|    0|               milf|[101, 4872, 1104,...|[101, 4872, 1104,...|\n",
      "|    0|           gonewild|[101, 196, 143, 1...|[101, 196, 143, 1...|\n",
      "|    0|           politics|[101, 6466, 1377,...|[101, 6466, 1377,...|\n",
      "|    0|               pics|[101, 146, 1267, ...|[101, 146, 1267, ...|\n",
      "|    0|           politics|[101, 2268, 117, ...|[101, 2268, 117, ...|\n",
      "|    0|            atheism|[101, 107, 19415,...|[101, 107, 19415,...|\n",
      "|    0|               gifs|[101, 4913, 7422,...|[101, 4913, 7422,...|\n",
      "|    0|              ducks|[101, 1109, 16627...|[101, 1109, 16627...|\n",
      "|    0|                CFB|[101, 146, 1156, ...|[101, 146, 1156, ...|\n",
      "|    0|              funny|[101, 1284, 2028,...|[101, 1284, 2028,...|\n",
      "|    0|              funny|[101, 138, 16723,...|[101, 138, 16723,...|\n",
      "|    0|              funny|[101, 1135, 112, ...|[101, 1135, 112, ...|\n",
      "|    0|          AskReddit|[101, 5749, 1207,...|[101, 5749, 1207,...|\n",
      "|    0|                aww|[101, 107, 107, 1...|[101, 107, 107, 1...|\n",
      "|    0|      todayilearned|[101, 157, 17656,...|[101, 157, 17656,...|\n",
      "|    0|PoliticalDiscussion|[101, 2082, 7691,...|[101, 2082, 7691,...|\n",
      "|    0|          AskReddit|[101, 6682, 1118,...|[101, 6682, 1118,...|\n",
      "|    0|       IncestComics|[101, 1422, 4126,...|[101, 1422, 4126,...|\n",
      "|    0|      todayilearned|[101, 157, 17656,...|[101, 157, 17656,...|\n",
      "+-----+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc = tsarc.withColumn('tokens_string', dense_format_udf(F.col('tokens')))\n",
    "tsarc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tokens_string: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc = tsarc.drop('tokens')\n",
    "tsarc = tsarc.drop('subreddit')\n",
    "tsarc = tsarc.drop('label')\n",
    "tsarc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       tokens_string|\n",
      "+--------------------+\n",
      "|[101, 1398, 1292,...|\n",
      "|[101, 4872, 1104,...|\n",
      "|[101, 196, 143, 1...|\n",
      "|[101, 6466, 1377,...|\n",
      "|[101, 146, 1267, ...|\n",
      "|[101, 2268, 117, ...|\n",
      "|[101, 107, 19415,...|\n",
      "|[101, 4913, 7422,...|\n",
      "|[101, 1109, 16627...|\n",
      "|[101, 146, 1156, ...|\n",
      "|[101, 1284, 2028,...|\n",
      "|[101, 138, 16723,...|\n",
      "|[101, 1135, 112, ...|\n",
      "|[101, 5749, 1207,...|\n",
      "|[101, 107, 107, 1...|\n",
      "|[101, 157, 17656,...|\n",
      "|[101, 2082, 7691,...|\n",
      "|[101, 6682, 1118,...|\n",
      "|[101, 1422, 4126,...|\n",
      "|[101, 157, 17656,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsarc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tsarc.write.csv('gs://sarc-bucket-5/tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
